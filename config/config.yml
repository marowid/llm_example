CHUNK_SIZE: 500
CHUNK_OVERLAP: 50
DATA_PATH: 'data/'
DB_FAISS_PATH: 'vectorstore/db_faiss2'

# MODEL_TYPE: 'mpt'
# MODEL_BIN_PATH: 'models/mpt-7b-instruct.ggmlv3.q8_0.bin'
MODEL_TYPE: 'llama'
MODEL_BIN_PATH: 'models/llama-2-7b-chat.ggmlv3.q2_K.bin'
MAX_NEW_TOKENS: 81920
RETURN_SOURCE_DOCUMENTS: True
VECTOR_COUNT: 2
TEMPERATURE: 0.01
MODEL_BATCH_SIZE: 4096
USE_GPU: False

EMBEDDINGS_MODEL_NAME: "sentence-transformers/all-MiniLM-L6-v2"
